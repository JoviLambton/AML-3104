{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Jovi Fez Bartolata</b>\n",
    "<br><b>C0869701</b>\n",
    "<br>\n",
    "<br><b>2023F-T3 AML 3104 - Neural Networks and Deep Learning</b>\n",
    "<br><b>Assignment 3</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Q1. Describe the decision tree classifier algorithm and how it works to make predictions.</b>\n",
    "<br>\n",
    "\n",
    "The Decision Trees classifier algorithm is a non-parametric supervised learning method. It creates a model that predicts the value of a target variable by learning simple decision rules inferred from the data features. Below is the high-level process on how it makes predicions:\n",
    "- Train the Decision Tree: Labeled data is used to train a decision tree. The label is used to identify the category where each record belongs to. The algorithim selects the best feature/attribute to split the data into smaller subsets, and this process is repeated until a stopping criterion is achieved.\n",
    "- Split the Nodes: For every node, the algorithm chooses the feature and the feature's threshold value that gives the best split of data based on a specific criterion such as Gini impurity.\n",
    "- Create the Child Nodes: The data is then divided into two child nodes based on the splitting criterion. One child is for the records that satisfy the criterion, and the other one for those that don't satisfy the condition.\n",
    "- Leaf Nodes: The algorithm will recursively split the nodes until a stopping criterion, such as maximum depth, is met. Once this is met, the node becomes the leaf node which represents a class label.\n",
    "- Predicting: To make predictions, the new data starts from the root node, follows the path through the tree based on the condition in each node, until it reaches the leaf node. The class label in the leaf node is the final prediction for the new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Q2. Provide a step-by-step explanation of the mathematical intuition behind decision tree classification.</b>\n",
    "<br>\n",
    "\n",
    "The high-level steps in decision tree classification are:\n",
    "- Use Attribute Selection Measures (ASM) to choose the best attribute to split the data.\n",
    "- That attribute becomes a decision node to split the data into smaller subsets.\n",
    "- Recursively repeat this process for every child node until: every tuple is associated with a single attribute value, or there's zero remaining attribute, or there are no other instances.\n",
    "\n",
    "\n",
    "Attribute Selection Measure, also known as splitting rules, is used to choose the splitting criterion that best divide the data. The ASM gives a rank to each attribute, and the best score attribute is chosen as the splitting attribute/feature.\n",
    "\n",
    "- Gini Index: It is computed by subtracting the sum of the squared probabilities of every class from one, hence, favors larger partitions. If there is perfect classification, the Gini Index is zero.\n",
    "<br><br>\n",
    "<img src=\"Gini Index.png\" width=\"200\"/>\n",
    "\n",
    "- Entropy: It is the measure of unpredictability or impurity in a dataset. An equally divided sample has an entropy of one, whereas a totally homegeneous sample has an entropy of zero.\n",
    "<br><br>\n",
    "<img src=\"Entropy.png\" width=\"300\"/>\n",
    "\n",
    "- Information Gain: It is the inverse of entropy and it quantifies the decrease in entropy. It calculates the difference between the entropy before the split and the mean entropy after the split of the data based on specific attribute values.\n",
    "<br><br>\n",
    "<img src=\"Information Gain.png\" width=\"300\"/>\n",
    "\n",
    "- Gain Ratio: It normalizes the information gain using Split Info, hence, it's able to handle the bias issue.\n",
    "<br><br>\n",
    "<img src=\"Gain Ratio.png\" width=\"300\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Q3. Explain how a decision tree classifier can be used to solve a binary classification problem.</b>\n",
    "<br>\n",
    "\n",
    "To use decision tree classifier for binary classifcation problem, the data must first be prepared such that the class label is binary (ex: 1/0, yes/no). The data should also contain features. In the training phase, the algorithm will determine the best feature to split the data into subsets. The features and threshold values are selected based on certain criterion to minimize impurity and gain most information. This process is repeated until a stopping criteria is met. The class assigned to the leaf node is based the majority class. For example, if the majority class is \"1\", the leaf node is labeled as \"1\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Q4. Discuss the geometric intuition behind decision tree classification and how it can be used to make predictions.</b>\n",
    "<br>\n",
    "\n",
    "Every decision that is made at the internal node results in the creation of a hyperplane. In other words, a hyperplane is created for each decision or data set split. In the example below, it can be seen that the decision boundaries are parallel to either X or Y axes, and have a decision surface for every leaf node (Yi)\n",
    "\n",
    "<img src=\"Decision Tree - Geometrical Sample.png\" width=\"400\"/>\n",
    "<br>\n",
    "<br>\n",
    "In this example, if the weight is less than b then the prediction is Yi = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Q5. Define the confusion matrix and describe how it can be used to evaluate the performance of a classification model.</b>\n",
    "<br>\n",
    "\n",
    "The confusion matrix shows the prediction summary in matrix form. It is used to shows the number of correct and incorrect predictions for each class. It is helpful in understanding the classes that the model confuses for other classes.\n",
    "\n",
    "- True Positive (TP) - The predicted value (positive) matches the actual value (positive).\n",
    "- True Negative (TN) - The predicted value (negative) matches the actual value (negative). \n",
    "- False Positive (FP) - The predicted value is positve but the actual value is negative.\n",
    "- False Negative (FN) - The predicted value is negative but the actual value is positve.\n",
    "\n",
    "Example:\n",
    "<br>\n",
    "<img src=\"Confusion Matrix Sample.png\" width=\"600\"/>\n",
    "- True Positive (TP) = 10 out of 100 were predicted to be postive and the actual value is positive.\n",
    "- True Negative (TN) = 40 out of 100 were predicted to be negative and the actual value is negative.\n",
    "- False Positive (FP) = 20 out of 100 were predicted to be postive but the actual value is negative.\n",
    "- False Negative (FN) = 30 out of 100 were predicted to be negative but the actual value is positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Q6. Provide an example of a confusion matrix and explain how precision, recall, and F1 score can be calculated from it.</b>\n",
    "<br>\n",
    "\n",
    "Example:\n",
    "<br>\n",
    "<img src=\"Confusion Matrix Sample.png\" width=\"600\"/>\n",
    "<br>True Positive (TP) = 10\n",
    "<br>True Negative (TN) = 40\n",
    "<br>False Positive (FP) = 20\n",
    "<br>False Negative (FN) = 30\n",
    "\n",
    "- Precision = TP / (TP + FP) = 10 / (10 + 20) = 0.33\n",
    "- Recall = TP / (TP + FN) = 10 / (10 + 30) = 0.25\n",
    "- F1 Score = (2 * Recall * Precision) / (Recall + Precision) = (2 * 0.25 * 0.33) / (0.25 + 0.33) = 0.2844"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Q7. Discuss the importance of choosing an appropriate evaluation metric for a classification problem and explain how this can be done.</b>\n",
    "<br>\n",
    "\n",
    "There are several evaluation metrics than can be used for a classification problem. Some of which are:\n",
    "- Accuracy: It measures how often the classifier make correct predictions. It is the ratio of the number of correct predictions and the total number of predictions.\n",
    "<br>\n",
    "<img src=\"Accuracy.png\" width=\"300\"/>\n",
    "<br>\n",
    "- Precision: It calculates the number of true positive cases out of all cases predicted to be positive.\n",
    "<br>\n",
    "<img src=\"Precision.png\" width=\"300\"/>\n",
    "<br>\n",
    "- Recall: It calculates the number the number of actual positive cases that the model was able to predict correctly. \n",
    "<br>\n",
    "<img src=\"Recall.png\" width=\"300\"/>\n",
    "<br>\n",
    "- F1 Score: It combines precision and recall metrics. Its values is maximum when precision and recall are equal.\n",
    "<br>\n",
    "<img src=\"F1 Score.png\" width=\"300\"/>\n",
    "<br>\n",
    "- AUC-ROC: The Area Under the Curve (AUC) measures the ability of a classifier to distinguish between classes. The Receiver Operator Characteristic (ROC) is a probability curve that plots the True Positive Rate (TPR) and the False Positive Rate (FPR) at different threshold values.\n",
    "\n",
    "Choosing the appropriate evaluation metrics for a classification problem depends on the use case and the objective of the model. If low false negative is more important, i.e., it should not miss any detection, then the model should have a high recall. If low false negative is the priority, i.e., it should not have incorrect detection, then the model should have a high precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Q8. Provide an example of a classification problem where precision is the most important metric, and explain why.</b>\n",
    "<br>\n",
    "\n",
    "In recommender systems, precision is more important because we want to avoid false positives. We want to mimimize recommendations, which the model predicts will be liked by the user, but the user actually doesn't like. This leads to bad customer experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Q9. Provide an example of a classification problem where recall is the most important metric and explain why.</b>\n",
    "<br>\n",
    "\n",
    "In fraud detection models, recall is more important because we want to avoid false negatives. We want to minimize instances where the model predicts that a transaction is legitimate when it is in fact fraudulent because it can result to monetary losses."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
